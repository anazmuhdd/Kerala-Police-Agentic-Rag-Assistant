{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee76b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_all_links():\n",
    "    # Use a session to preserve cookies\n",
    "    session = requests.Session()\n",
    "    \n",
    "    # Step 1: Visit homepage to get cookies\n",
    "    main_url = \"https://keralapolice.gov.in\"\n",
    "    session.get(main_url, verify=False)  # verify=False to ignore SSL cert issues (use cautiously)\n",
    "    print(\"âœ… Fetched homepage (cookies set)\")\n",
    "\n",
    "    # Step 2: Now request the English version in the same session\n",
    "    en_url = \"https://keralapolice.gov.in/switch/language/en\"\n",
    "    response = session.get(en_url, verify=False)\n",
    "    print(\"âœ… Fetched English page\")\n",
    "\n",
    "    # Optional: Check if it's really in English\n",
    "    if \"About Kerala Police\" in response.text:\n",
    "        print(\"âœ… Confirmed: Page is in English\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Warning: May still be in Malayalam\")\n",
    "\n",
    "    # Parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    links = soup.find_all('a')\n",
    "    linkaddrs = [link.get('href') for link in links if link.get('href')]\n",
    "    return linkaddrs\n",
    "\n",
    "\n",
    "# Run it\n",
    "linkaddrs = get_all_links()\n",
    "print(\"\\nðŸ”— Extracted Links:\")\n",
    "for link in linkaddrs:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e832da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# Load environment\n",
    "dotenv.load_dotenv()\n",
    "NVIDIA_API_KEY = os.getenv(\"nvidia_api_key\")\n",
    "\n",
    "if not NVIDIA_API_KEY:\n",
    "    raise ValueError(\"NVIDIA_API_KEY not found in .env\")\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key=NVIDIA_API_KEY,\n",
    ")\n",
    "base_url = \"https://keralapolice.gov.in\"\n",
    "session = requests.Session()\n",
    "\n",
    "def extract_main_content(page_path: str):\n",
    "   \n",
    "    try:\n",
    "        page_path=page_path.strip()\n",
    "        session.get(f\"{base_url}\", timeout=10, verify=False)\n",
    "        print(\"Initial page loaded\")\n",
    "        session.get(f\"{base_url}/switch/language/en\",verify=False)\n",
    "        print(\"loaded english content\")\n",
    "        full_url = f\"{base_url}/{page_path}\" if page_path else base_url\n",
    "        response = session.get(full_url, timeout=10, verify=False)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        for tag in soup([\"script\", \"style\", \"nav\", \"footer\", \"header\", \"aside\"]):\n",
    "            tag.decompose()\n",
    "\n",
    "        title = soup.title.string.strip() if soup.title else \"Kerala Police\"\n",
    "\n",
    "        main_content = soup.find(\"body\")\n",
    "\n",
    "        if main_content:\n",
    "            lines = (line.strip() for line in main_content.stripped_strings)\n",
    "            body_text = \"\\n\".join(line for line in lines if line)\n",
    "        else:\n",
    "            print(\"No content found\")\n",
    "            body_text = \"\"\n",
    "            return 0\n",
    "\n",
    "        return {\n",
    "            \"url\": full_url,\n",
    "            \"title\": title,\n",
    "            \"content\": body_text\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {full_url}: {e}\")\n",
    "        return {\"url\": full_url, \"title\": \"\", \"content\": \"\"}\n",
    "\n",
    "\n",
    "data = extract_main_content(\"page/vision-mission\")\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an expert data curator for a making RAG (Retrieval-Augmented Generation) document retrieval system.\n",
    "Your task is to extract structured, useful information from the Kerala Police website.\n",
    "You will be given the content of a webpage, and your task is to extract and return the following:\n",
    "    -extract all the content that will be relevant for building and provide accordingly in the output.\n",
    "    -if found like different topics, then give all the diffrent topics as differnt title and content.\n",
    "    -extract the information, and give the content intelligently, you can modify the content you extracted according to my use case.\n",
    "    -I will be extracting the title you provided as the documnet title for making rag document embeddi.\n",
    "    -I will be extracting the content you provided as the documnet content for making rag document embeddi.\n",
    "Given the following webpage content:\n",
    "\n",
    "TITLE: {data['title']}\n",
    "CONTENT:\n",
    "{data['content']}\n",
    "\n",
    "Extract the contents in **valid JSON format only** (no markdown, no explanation). If found or have multiple contents, you can output the each content in this format:\n",
    "\n",
    "{{\n",
    "  \"Title\": \"Content you extracted\",\n",
    "  \"Content\": \"Content you extracted\"\n",
    "  \n",
    "}}\n",
    "\n",
    "Important:\n",
    "- Only include links that are internal (start with / or https://keralapolice.gov.in)\n",
    "- Do not invent information.\n",
    "- If a field is unknown, use empty string or empty list.\n",
    "- Output ONLY the JSON object.\n",
    "\"\"\"\n",
    "if data:\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"qwen/qwen3-coder-480b-a35b-instruct\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.1,\n",
    "            top_p=0.7,\n",
    "            max_tokens=1024,\n",
    "        )\n",
    "        result = completion.choices[0].message.content.strip()\n",
    "\n",
    "        # Try to parse JSON (in case LLM adds ```json...```)\n",
    "        if result.startswith(\"```json\"):\n",
    "            result = result[7:-3].strip()\n",
    "        elif result.startswith(\"```\"):\n",
    "            result = result[3:-3].strip()\n",
    "\n",
    "        structured_data = json.loads(result)\n",
    "        print(json.dumps(structured_data, indent=2, ensure_ascii=False))\n",
    "        filename = \"vision and mission.txt\"\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(json.dumps(structured_data, indent=2, ensure_ascii=False))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        print(\"Raw LLM output:\")\n",
    "        print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a2038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rag dataset prepare to csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "folder=\"data\"\n",
    "\n",
    "#open all the files in the folder\n",
    "files = [f for f in os.listdir(folder) if f.endswith(\".txt\")]\n",
    "\n",
    "print(\"Found\", len(files), \"files in\", folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103db703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "NVIDIA_API_KEY = os.getenv(\"nvidia_api_key\")\n",
    "\n",
    "if not NVIDIA_API_KEY:\n",
    "    raise ValueError(\"NVIDIA_API_KEY not found in .env\")\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key=NVIDIA_API_KEY,\n",
    ")\n",
    "def chunksplit(data):\n",
    "    prompt=f\"\"\"\n",
    "    You are an expert data curator for a making RAG (Retrieval-Augmented Generation) document retrieval system.\n",
    "    You will be given a dictionary with the following keys:\n",
    "        Title: The title of the document.\n",
    "        Content: The content of the document.\n",
    "        \n",
    "    the content of the documnet is greater than 250 words.\n",
    "    your job is to return the content in chunks of 250 words in the following format of multiple dictionary in a dictionary/json as in the format without losing the\n",
    "    meaning of the content, that is dont trim the content upto just 249 words, the content ust have a completeness. dont just trim acoording to the size of words, output the data \n",
    "    in the following, dont include any things, return the list only:\n",
    "    {{\n",
    "        {{\n",
    "            \"Title\": \"The title of the data\",\n",
    "            \"Content\": Trimmed content 1\n",
    "        }},\n",
    "        {{\n",
    "            \"Title\": \"The title of the data\",\n",
    "            \"Content\": Trimmed content 2\n",
    "        }},\n",
    "        etc\n",
    "    }}\n",
    "    You must not modify or remove it. Make it efficeint trimming for the RAG.\n",
    "\n",
    "    The dictionary data:\n",
    "    {data}\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"prompt given:\\n\",prompt)\n",
    "        completion= client.chat.completions.create(\n",
    "            model=\"openai/gpt-oss-120b\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            top_p=0.2,\n",
    "            stream=False\n",
    "        )\n",
    "        reasoning = getattr(completion.choices[0].message, \"reasoning_content\", None)\n",
    "        if reasoning:\n",
    "            print(reasoning)\n",
    "        print(\"Reply from llm: \",completion.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        print(\"LLM error: \",e)\n",
    "    reply=completion.choices[0].message.content\n",
    "    if reply.startswith(\"```json\"):\n",
    "            reply = reply[7:-3].strip()\n",
    "    elif reply.startswith(\"```\"):\n",
    "            reply = reply[3:-3].strip()\n",
    "    structured_data=json.loads(reply)\n",
    "    print(structured_data)\n",
    "    return structured_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86679b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"Title\", \"Content\"])\n",
    "json_datas=[]\n",
    "fileerror=[]\n",
    "for file in files:\n",
    "    with open(os.path.join(folder, file), \"r\") as f:\n",
    "        try:\n",
    "            json_data = json.load(f)\n",
    "            \n",
    "            if(len(json_data[\"Content\"].split())>250):\n",
    "                print(\"file: \",file)\n",
    "                datas=chunksplit(json_data)\n",
    "                for data in datas:\n",
    "                    jsonofdata=data\n",
    "                    json_datas.append(jsonofdata)\n",
    "                    print(\"appended data:\", jsonofdata[\"Title\"])\n",
    "            else:\n",
    "                json_datas.append(json_data)\n",
    "            print(\"Successfully appended file to datatset:\",file)\n",
    "        except Exception as e:\n",
    "            print(\"file error: \",file)\n",
    "            fileerror.append(file)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a22118db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(json_datas)\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(json_datas)\n",
    "df.to_csv(\"dataset.csv\", index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ff2d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Title",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Content",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "d9ab97c3-0e77-4dac-93b8-2c83855da16c",
       "rows": [
        [
         "count",
         "221",
         "221"
        ],
        [
         "unique",
         "211",
         "221"
        ],
        [
         "top",
         "About Kerala Police",
         "At present, an ATM Counter of State Bank of India is functioning at Battalion Headquarters. It was inaugurated during the year 2014."
        ],
        [
         "freq",
         "3",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>211</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>About Kerala Police</td>\n",
       "      <td>At present, an ATM Counter of State Bank of In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Title                                            Content\n",
       "count                   221                                                221\n",
       "unique                  211                                                221\n",
       "top     About Kerala Police  At present, an ATM Counter of State Bank of In...\n",
       "freq                      3                                                  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df.head()\n",
    "#sort df by title column alphabetically\n",
    "df = df.sort_values(by=\"Title\").reset_index(drop=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e70694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed.anas@acsiatech.com/Projects/Tasks/RAG_PROJECT/myenv/lib/python3.10/site-packages/langchain_nvidia_ai_endpoints/_common.py:234: UserWarning: Found nvidia/llama-3.2-nemoretriever-300m-embed-v2 in available_models, but type is unknown and inference may fail.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents prepared: 221\n",
      "âœ… Vector store created with NVIDIA embeddings and persisted.\n"
     ]
    }
   ],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import os\n",
    "\n",
    "# âœ… Use valid NVIDIA embedding model\n",
    "embeddings = NVIDIAEmbeddings(\n",
    "    model=\"nvidia/llama-3.2-nemoretriever-300m-embed-v2\",      # â† Correct model name\n",
    "    api_key=\"\",  # â† Proper env var\n",
    "    truncate=\"END\"  # or \"NONE\"; \"END\" is safer for long texts\n",
    ")\n",
    "\n",
    "# Build documents\n",
    "docs = []\n",
    "for index, row in df.iterrows():\n",
    "    doc = Document(\n",
    "        page_content=row['Content'],\n",
    "        metadata={\"title\": row[\"Title\"], \"content\": row[\"Content\"]}\n",
    "    )\n",
    "    docs.append(doc)\n",
    "\n",
    "print(f\"Total documents prepared: {len(docs)}\")\n",
    "\n",
    "# Create & persist Chroma DB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"vector_store\",\n",
    "    persist_directory=\"vector_store\"\n",
    ")\n",
    "print(\"âœ… Vector store created with NVIDIA embeddings and persisted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b80edf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â†’ Similarity:\n",
      "{'title': 'About Kerala Police', 'content': \"Kerala State Police is the law enforcement agency for the State of Kerala with its Headquarters at Thiruvananthapuram, the State Capital. Kerala Police has a reputation for being one of the best-managed state police forces in the country and is one of the top-ranking states in terms of maintenance of law and order. Kerala Police is also one of the first Police departments in South Asia to implement community policing through an enactment. It is popularly known as 'Janamaithri' Policing, which literally translates to people-friendly Policing. Kerala Police registers the highest number of cognizable offences in the country, next only to the National Capital Territory of Delhi. This has to be viewed in perspective of the relatively peaceful image of the state. This is a reflection of the good practice adopted by the state in registering every cognizable instance reported at the Police station level and dealing with the crimes and offenders legally. Kerala Police has been the fountain head of several police reforms and innovative schemes in the country. A new Kerala Police Act enacted in 2011 was a guiding light for many other state police forces in the country to draft their own local Police Acts. The avant-garde provisions of the Act, which enable setting up of Police Establishment Board, Police Complaints Authority, State Security Commission, Police Welfare Bureau, Community Policing, etc., have given it a status of a modern day treatise on Policing philosophy.\"}\n",
      "{'title': 'History of Kerala Police - Former Chiefs', 'content': 'List of former chiefs of Kerala Police with their tenure dates: Dr. Shaik Darvesh Saheb IPS (01-07-2023 to 30-06-2025), Anil Kant IPS (01-07-2021 to 30-06-2023), Loknath Behera IPS (01-06-2016 to 06-05-2017 and 01-07-2017 to 30-06-2021), Dr. T.P Senkumar IPS (01-06-2015 to 31-05-2016 and 06-05-2017 to 30-06-2017), K.S Balasubramanian IPS (01-09-2012 to 31-05-2015), Jacob Punnoose IPS (01-12-2008 to 31-08-2012), Raman Srivastava IPS (01-02-2005 to 30-11-2008), P.K Hormese Tharakan IPS (31-05-2003 to 31-01-2005), K.J Joseph IPS (31-01-2002 to 31-05-2003), W. Joseph Dawson IPS (31-10-2001 to 31-01-2002), R. Padmanabhan IPS (31-05-2001 to 31-10-2001), P.R Chandran IPS (26-07-2000 to 31-05-2001), B.S Sasthri IPS (31-03-1998 to 25-07-2000), C.A Chaly IPS (30-06-1997 to 31-03-1998), M. Adbul Sathar Kunju IPS (05-06-1997 to 30-06-1997), R. Radhakrishanan IPS (1996 â€“ 1997), K.V Rajagopalan Nair IPS (1995 â€“ 1996), T.V Madhusudanan IPS (1994 â€“ 1995), R. Jayaram Padikkal IPS (1993 â€“ 1994), C. Subramaniam IPS (1991 â€“ 1993), A.V Venkatachalam IPS (1991), Raj Gopal Narayan IPS (1988 â€“ 1991), K. John Mathai IPS (1989), M. K. Joseph IPS (1983 â€“ 1988), P. Vijayan IPS (1982 â€“ 1983), T.A.S Iyer IPS (1978 â€“ 1982), V. Subramanian IPS (1980), V.N Rajan IPS (1974 -1978), M. Singaravelu IPS (1972 â€“ 1974), M Gopalan IPS (1967 -1972), N. Rama Iyer IPS (1964-1967), V.P Nair IPS (1961-1964), K N R Sreenivasan Iyer IPS (1959), M. Krishna Menon IPS (1957 â€“ 1961), Chandrasekaran Nair IPS (1956 - 1957). Last updated on Tuesday 1st of July 2025 09:26:44 AM.'}\n",
      "{'content': 'Kerala Police aspires to achieve excellence in the quality of criminal law enforcement, public order, and citizen safety by pioneering the adoption of the latest technology in the fields of forensics, evidence collection, public order maintenance, traffic enforcement, and police administration within the next 10 years.', 'title': 'Vision Statement'}\n",
      "{'content': 'Kerala Police is headed by the State Police Chief, who is the senior most Indian Police Service officer in the State and holds the rank of Director General of Police. The State Police Chief is designated as the Head of the department for all administrative and operational purposes. The police force is assisted by officers and subject domain experts across the state for effective administration.', 'title': 'About Kerala Police'}\n",
      "{'title': 'Mission Statement', 'content': \"Kerala Police is committed to achieving the highest level of citizen satisfaction by striving to provide world-class quality of police services through prompt redressal of grievances, transparent and fair enforcement of law, maintenance of order by protecting citizens' rights and individual dignity, and incessant endeavor to enhance public safety.\"}\n",
      "â†’ Similarity:\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "[###] Your request cannot be validated, it is incorrect. detail=Input list must be non-empty and all elements must be non-empty.\n{'error': 'Your request cannot be validated, it is incorrect. detail=Input list must be non-empty and all elements must be non-empty.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter a query: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâ†’ Similarity:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      6\u001b[0m    \u001b[38;5;28mprint\u001b[39m(r\u001b[38;5;241m.\u001b[39mmetadata)\n",
      "File \u001b[0;32m~/Projects/Tasks/RAG_PROJECT/myenv/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:350\u001b[0m, in \u001b[0;36mChroma.similarity_search\u001b[0;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    335\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    339\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    340\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m        List[Document]: List of documents most similar to the query text.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/Projects/Tasks/RAG_PROJECT/myenv/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:439\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[0;34m(self, query, k, filter, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__query_collection(\n\u001b[1;32m    432\u001b[0m         query_texts\u001b[38;5;241m=\u001b[39m[query],\n\u001b[1;32m    433\u001b[0m         n_results\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    437\u001b[0m     )\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__query_collection(\n\u001b[1;32m    441\u001b[0m         query_embeddings\u001b[38;5;241m=\u001b[39m[query_embedding],\n\u001b[1;32m    442\u001b[0m         n_results\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    446\u001b[0m     )\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "File \u001b[0;32m~/Projects/Tasks/RAG_PROJECT/myenv/lib/python3.10/site-packages/langchain_nvidia_ai_endpoints/embeddings.py:174\u001b[0m, in \u001b[0;36mNVIDIAEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    173\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Input pathway for query embeddings.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/Tasks/RAG_PROJECT/myenv/lib/python3.10/site-packages/langchain_nvidia_ai_endpoints/embeddings.py:159\u001b[0m, in \u001b[0;36mNVIDIAEmbeddings._embed\u001b[0;34m(self, texts, model_type)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimensions:\n\u001b[1;32m    157\u001b[0m     payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimensions\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimensions\n\u001b[0;32m--> 159\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_req\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpayload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    164\u001b[0m result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/Projects/Tasks/RAG_PROJECT/myenv/lib/python3.10/site-packages/langchain_nvidia_ai_endpoints/_common.py:641\u001b[0m, in \u001b[0;36m_NVIDIAClient.get_req\u001b[0;34m(self, payload, extra_headers)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_req\u001b[39m(\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    637\u001b[0m     payload: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m {},\n\u001b[1;32m    638\u001b[0m     extra_headers: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m {},\n\u001b[1;32m    639\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m    640\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Post to the API.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m     response, session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait(response, session)\n",
      "File \u001b[0;32m~/Projects/Tasks/RAG_PROJECT/myenv/lib/python3.10/site-packages/langchain_nvidia_ai_endpoints/_common.py:416\u001b[0m, in \u001b[0;36m_NVIDIAClient._post\u001b[0;34m(self, invoke_url, payload, extra_headers)\u001b[0m\n\u001b[1;32m    412\u001b[0m session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_session_fn()\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m response \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__add_authorization(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_inputs)\n\u001b[1;32m    415\u001b[0m )\n\u001b[0;32m--> 416\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response, session\n",
      "File \u001b[0;32m~/Projects/Tasks/RAG_PROJECT/myenv/lib/python3.10/site-packages/langchain_nvidia_ai_endpoints/_common.py:511\u001b[0m, in \u001b[0;36m_NVIDIAClient._try_raise\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    509\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_error(rd)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# todo: raise as an HTTPError\u001b[39;00m\n\u001b[0;32m--> 511\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: [###] Your request cannot be validated, it is incorrect. detail=Input list must be non-empty and all elements must be non-empty.\n{'error': 'Your request cannot be validated, it is incorrect. detail=Input list must be non-empty and all elements must be non-empty.'}"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "\n",
    "    print(\"â†’ Similarity:\")\n",
    "    for r in vectorstore.similarity_search(query, k=5):\n",
    "       print(r.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ece59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
